{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb69976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "import os    \n",
    "import cv2\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg19, VGG19_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c876db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, n_features,norm_layer=nn.InstanceNorm2d):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(n_features, n_features, 3),\n",
    "            norm_layer(n_features), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(n_features, n_features, 3),\n",
    "            norm_layer(n_features)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self,num_residual_blocks=6,default_norm_layer=nn.InstanceNorm2d):\n",
    "        super(ResnetGenerator, self).__init__()  \n",
    "        \n",
    "        def conv_block(in_channels,out_channels,kernel_size,stride,padding,norm_layer=default_norm_layer,padding_mode='reflect'):\n",
    "            if norm_layer != False:\n",
    "                return [nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,padding_mode=padding_mode),\n",
    "                        norm_layer(out_channels),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                return [nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,padding_mode=padding_mode),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "            \n",
    "        # Used in upsampling\n",
    "        def deconv_block(in_channels,out_channels,kernel_size=3,stride=2,padding=1, output_padding=1,norm_layer=default_norm_layer):\n",
    "            if norm_layer != False:\n",
    "                return [nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride,padding,output_padding),\n",
    "                        norm_layer(out_channels),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                return [nn.ConvTranspose2d(in_channels,out_channels,kernel_size,stride,padding,output_padding),\n",
    "                        nn.ReLU(inplace=True)]\n",
    "         \n",
    "        output_layer = [nn.Conv2d(in_channels=64,out_channels=3,kernel_size=7,padding=3,padding_mode='reflect'),nn.Tanh()]\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *conv_block(in_channels=3,out_channels=64,kernel_size=7,stride=1,padding=3,padding_mode='reflect'),\n",
    "            *conv_block(in_channels=64,out_channels=128,kernel_size=3,stride=2,padding=1,padding_mode='zeros'),\n",
    "            *conv_block(in_channels=128,out_channels=256,kernel_size=3,stride=2,padding=1,padding_mode='zeros'),\n",
    "            *[ResidualBlock(256,default_norm_layer)]*num_residual_blocks,\n",
    "            *deconv_block(in_channels=256,out_channels=128),\n",
    "            *deconv_block(in_channels=128,out_channels=64),\n",
    "            *output_layer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634db146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_BA_9 = ResnetGenerator(9).to(device)\n",
    "# G_BA_15 = ResnetGenerator(15).to(device)\n",
    "# G_BA_30 = ResnetGenerator(30).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4fc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_BA_9.load_state_dict(torch.load('GBA 9 rblocks'))\n",
    "# G_BA_15.load_state_dict(torch.load('GBA 15 rblocks'))\n",
    "# G_BA_30.load_state_dict(torch.load('GBA 30 rblocks'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_BA_impress = ResnetGenerator(9).to(device)\n",
    "# G_BA_impress.load_state_dict(torch.load('GBA-landscape-epoch45'))\n",
    "G_BA_impress = ResnetGenerator(15).to(device)\n",
    "G_BA_impress.load_state_dict(torch.load('GBA 15 rblocks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c13170",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_video_dir = './source_videos/demo3.mp4'\n",
    "video_frames_dir = \"./source_frames/demo3/\"\n",
    "\n",
    "vidcap = cv2.VideoCapture(source_video_dir)\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(video_frames_dir+str(count)+\".jpg\", image)     # save frame as JPG file\n",
    "    return hasFrames\n",
    "sec = 0\n",
    "fps_source = 24\n",
    "frameRate = 1/fps_source\n",
    "count=1\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames_dir = \"./source_frames/demo3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e01e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = (256*2,256*2)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(imsize),  # scale imported image\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # match Normalize params of loaded model\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # match Normalize params of loaded model\n",
    "])\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "#                                                      std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "#                                 transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "#                                                      std = [ 1., 1., 1. ]),\n",
    "#                                ])\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.5, 1/0.5, 1/0.5 ]),\n",
    "                                transforms.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285da548",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = video_frames_dir + str(100) + '.jpg'\n",
    "with torch.no_grad():\n",
    "    G_BA_impress.eval()\n",
    "    original_B = image_loader(img_name).to(device)\n",
    "    generated_A = G_BA_impress(original_B).detach()\n",
    "#     generated_A = F.interpolate(generated_A, scale_factor=3, mode='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(invTrans(generated_A).squeeze(0).cpu().permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf871793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from os.path import isfile, join\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "frame_files = [f for f in os.listdir(video_frames_dir) if isfile(join(video_frames_dir, f))]\n",
    "generated_frames = []\n",
    "with torch.no_grad():\n",
    "    G_BA_impress.eval()\n",
    "    for i in tqdm(range(len(frame_files))):\n",
    "        content_img = video_frames_dir + str(i+1) + '.jpg'\n",
    "        original_B = image_loader(content_img).to(device)\n",
    "        generated_A = G_BA_impress(original_B).detach()\n",
    "        generated_frames.append(invTrans(generated_A).squeeze(0).cpu().permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 60\n",
    "pathOut = 'video_0.mp4'\n",
    "generated_frames_array = [(i*255).numpy().round().astype(np.uint8)[:, :, ::-1] for i in generated_frames]\n",
    "out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, imsize[::-1])\n",
    "for i in range(len(generated_frames_array)):\n",
    "    out.write(generated_frames_array[i])\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
